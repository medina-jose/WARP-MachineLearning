{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python import debug as tf_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  1.5.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import json\n",
    "import random\n",
    "import itertools\n",
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '\\t', '\\n', '\\x0b', '\\x0c', '\\r', ' ']\n"
     ]
    }
   ],
   "source": [
    "import string \n",
    "from collections import Counter\n",
    "characters = sorted(list(set(Counter(string.ascii_letters).keys())))\n",
    "digits = sorted(list(set(Counter(string.digits).keys())))\n",
    "whitespace = sorted(list(set(Counter(string.whitespace).keys())))\n",
    "characters.append(digits)\n",
    "characters.append(whitespace)\n",
    "print(characters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[14, 13, 13, ..., 13, 13, 13],\n",
      "       [13, 13, 13, ..., 13, 13, 13],\n",
      "       [13, 14, 14, ..., 13, 12, 12],\n",
      "       ...,\n",
      "       [ 6,  6,  6, ..., 11, 11, 11],\n",
      "       [ 6,  6,  6, ..., 11, 11, 11],\n",
      "       [ 6,  6,  6, ..., 11, 11, 11]], dtype=uint8), b'./dataset/dummy/json/andrewlloydwebberandtimrice_jesuschristsuperstar_0001.json')\n",
      "(array([[ 6,  6,  6, ...,  7,  6,  6],\n",
      "       [ 6,  6,  6, ...,  7,  6,  6],\n",
      "       [ 6,  6,  6, ...,  7,  7,  7],\n",
      "       ...,\n",
      "       [80, 78, 76, ...,  4,  4,  4],\n",
      "       [82, 77, 73, ...,  4,  4,  4],\n",
      "       [85, 77, 70, ...,  4,  4,  4]], dtype=uint8), b'./dataset/dummy/json/chic_cestchic_0001.json')\n",
      "(array([[3, 2, 2, ..., 3, 3, 2],\n",
      "       [3, 2, 2, ..., 3, 3, 2],\n",
      "       [3, 3, 3, ..., 3, 3, 2],\n",
      "       ...,\n",
      "       [3, 3, 2, ..., 2, 2, 2],\n",
      "       [3, 3, 2, ..., 2, 2, 2],\n",
      "       [4, 3, 1, ..., 2, 2, 2]], dtype=uint8), b'./dataset/dummy/json/ciare_likeaboy_0002.json')\n",
      "(array([[11, 11, 11, ..., 13, 14, 14],\n",
      "       [11, 11, 11, ..., 13, 14, 14],\n",
      "       [11, 11, 11, ..., 13, 14, 14],\n",
      "       ...,\n",
      "       [48, 46, 46, ..., 11, 11, 10],\n",
      "       [46, 44, 44, ..., 11, 11, 11],\n",
      "       [45, 43, 43, ..., 11, 11, 11]], dtype=uint8), b'./dataset/dummy/json/frankzappa_waka-jawakahotrats_0001.json')\n",
      "(array([[ 13,  13,  13, ...,  15,  15,  15],\n",
      "       [ 13,  12,  12, ...,  15,  15,  15],\n",
      "       [ 12,  12,  12, ...,  15,  15,  15],\n",
      "       ...,\n",
      "       [ 71,  83,  75, ...,  13,  13,  13],\n",
      "       [119, 128, 118, ...,  13,  12,  13],\n",
      "       [133, 134, 134, ...,  13,  13,  13]], dtype=uint8), b'./dataset/dummy/json/gilscottheron_nothingnew_0001.json')\n",
      "(array([[ 7,  7,  6, ...,  6,  6,  7],\n",
      "       [ 7,  7,  6, ...,  6,  6,  6],\n",
      "       [ 6,  6,  6, ...,  6,  6,  6],\n",
      "       ...,\n",
      "       [23, 23, 22, ...,  6,  6,  6],\n",
      "       [22, 21, 21, ...,  6,  6,  6],\n",
      "       [22, 21, 21, ...,  6,  6,  6]], dtype=uint8), b'./dataset/dummy/json/gwenmccrae_onmyway_0001.json')\n",
      "(array([[16, 16, 16, ..., 17, 18, 18],\n",
      "       [16, 16, 16, ..., 17, 18, 17],\n",
      "       [16, 16, 16, ..., 17, 17, 17],\n",
      "       ...,\n",
      "       [14, 14, 14, ..., 16, 16, 16],\n",
      "       [14, 14, 14, ..., 16, 16, 16],\n",
      "       [14, 14, 14, ..., 16, 16, 16]], dtype=uint8), b'./dataset/dummy/json/madvillain_madvillainy_0001.json')\n",
      "(array([[12, 12, 12, ..., 12, 12, 12],\n",
      "       [12, 12, 12, ..., 12, 12, 12],\n",
      "       [13, 12, 12, ..., 13, 13, 13],\n",
      "       ...,\n",
      "       [12, 12, 12, ...,  8,  8,  8],\n",
      "       [12, 12, 12, ...,  8,  8,  8],\n",
      "       [12, 12, 12, ...,  8,  8,  8]], dtype=uint8), b'./dataset/dummy/json/oneohtrixpointnever_commissionsii_0002.json')\n",
      "(array([[ 3,  3,  3, ...,  3,  2,  3],\n",
      "       [ 3,  3,  3, ...,  3,  2,  3],\n",
      "       [ 3,  3,  3, ...,  3,  3,  3],\n",
      "       ...,\n",
      "       [12, 13, 14, ...,  3,  3,  3],\n",
      "       [14, 15, 16, ...,  3,  3,  3],\n",
      "       [17, 17, 19, ...,  3,  3,  3]], dtype=uint8), b'./dataset/dummy/json/stvincent_actor_0001.json')\n",
      "(array([[ 6,  6,  6, ...,  6,  6,  6],\n",
      "       [ 6,  6,  6, ...,  6,  6,  6],\n",
      "       [ 6,  6,  6, ...,  6,  6,  6],\n",
      "       ...,\n",
      "       [14, 13, 12, ...,  6,  6,  6],\n",
      "       [15, 13, 12, ...,  6,  6,  6],\n",
      "       [16, 13, 12, ...,  6,  6,  6]], dtype=uint8), b'./dataset/dummy/json/therollingstones_tattooyou_0001.json')\n",
      "End of training dataset.\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, directory_path, img_height, img_width, batch_size):\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # get sample filenames\n",
    "        img_directory_path = directory_path + '/img/'\n",
    "        label_directory_path = directory_path + '/json/' \n",
    "        self.img_filenames = []\n",
    "        self.label_filenames = []\n",
    "        self.imgs = []\n",
    "        for filename in os.listdir(img_directory_path):\n",
    "            img_filenames.append(img_directory_path + filename)\n",
    "            imgs.append(cv2.imread(img_directory_path + filename, 0))\n",
    "        for filename in os.listdir(label_directory_path):\n",
    "            label_filenames.append(label_directory_path + filename)\n",
    "         \n",
    "        # store filenames as tensors\n",
    "        self.img_filename_tensors = tf.constant(img_filenames)\n",
    "        self.label_tensors = tf.constant(label_filenames)\n",
    "        self.img_tensors = tf.constant(np.asarray(imgs))\n",
    "        self.dataset = tf.data.Dataset.from_tensor_slices((self.img_tensors, self.label_tensors))\n",
    "    \n",
    "    def next_batch(self, batch_size):\n",
    "        return\n",
    " \n",
    "    \n",
    "# get sample filenames\n",
    "directory_path = './dataset/dummy'\n",
    "img_directory_path = directory_path + '/img/'\n",
    "label_directory_path = directory_path + '/json/' \n",
    "img_filenames = []\n",
    "label_filenames = []\n",
    "imgs = []\n",
    "for filename in os.listdir(img_directory_path):\n",
    "    img_filenames.append(img_directory_path + filename)\n",
    "    imgs.append(cv2.imread(img_directory_path + filename, 0))\n",
    "for filename in os.listdir(label_directory_path):\n",
    "    label_filenames.append(label_directory_path + filename)\n",
    "\n",
    "# store filenames as tensors\n",
    "imgs = tf.constant(np.asarray(imgs))\n",
    "img_tensors = tf.constant(img_filenames)\n",
    "label_tensors = tf.constant(label_filenames)\n",
    "\n",
    "#dataset = Dataset('./dataset/dummy', 256, 256, 1)   \n",
    "#tf_dataset = tf.data.Dataset.from_tensor_slices((dataset.img_tensors, dataset.label_tensors))   \n",
    "tf_dataset = tf.data.Dataset.from_tensor_slices((imgs, label_tensors))   \n",
    "iterator = tf.data.Iterator.from_structure(tf_dataset.output_types, tf_dataset.output_shapes)\n",
    "next_sample = iterator.get_next()\n",
    "init = (tf.global_variables_initializer(), iterator.make_initializer(tf_dataset))\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "#sess = tf_debug.LocalCLIDebugWrapperSession(sess)\n",
    "sess.run(init)\n",
    "while True:\n",
    "    try: \n",
    "        sample = sess.run(next_sample)\n",
    "        print(sample)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print(\"End of training dataset.\")\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Layers & Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Init Weights\n",
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=.1)\n",
    "    return tf.Variable(init_random_dist)\n",
    "\n",
    "# Init Bias\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1,shape=shape);\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "# Conv2D\n",
    "# x: [batch size, height, width, # of channels]\n",
    "# W: [height filter, width filter, # of input channels, # of output channels]\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "# Pooling\n",
    "# x: [batch size, height, width, # of channels]\n",
    "# ksize: size of the window for each dimension of the input tensor\n",
    "# strides: \n",
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1] , strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "# Convolutional Layer\n",
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W)+b)\n",
    "\n",
    "# Normal (Fully Connected) Layer\n",
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return (tf.matmul(input_layer, W)+b)\n",
    "\n",
    "# Placeholders\n",
    "x = tf.placeholder(tf.float32, shape=[None, 65536])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, len(letters)])\n",
    "\n",
    "# Layers\n",
    "x_image = tf.reshape(x, [-1,256,256,1])\n",
    "convo_1 = convolutional_layer(x_image, shape=[5,5,1,32])\n",
    "pool_1 = max_pool_2by2(convo_1)\n",
    "convo_2 = convolutional_layer(pool_1, shape=[5,5,32,64])\n",
    "pool_2 = max_pool_2by2(convo_2)\n",
    "flat_1 = tf.reshape(pool_2, [-1,256*256*64])\n",
    "full_layer_one = tf.nn.relu(normal_full_layer(flat_1, 1024))\n",
    "\n",
    "# Dropout\n",
    "# used to prevent overfitting\n",
    "hold_prob = tf.placeholder(tf.float32)\n",
    "full_one_dropout = tf.nn.dropout(full_layer_one, keep_prob=hold_prob)\n",
    "y_pred = normal_full_layer(full_one_dropout, len(letters))\n",
    "\n",
    "# loss function\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true, logits=y_pred))\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train = optimizer.minimize(cross_entropy)\n",
    "\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile\n",
    "\n",
    "def images_to_tensors(img_paths):\n",
    "    img_queue = tf.train.string_input_producer(img_paths)  \n",
    "    reader = tf.WholeFileReader()\n",
    "    keys, values = reader.read_up_to(img_queue, tf.cast(img_queue.size(), dtype=tf.int64))\n",
    "    images = tf.Variable([])\n",
    "    fn = lambda x: images.append(tf.image.decode_png(x))\n",
    "    tf.map_fn = (fn, values)\n",
    "    fn2 = lambda x: print(x)\n",
    "    tf.map_fn(fn2, images)\n",
    "    return images\n",
    "\n",
    "def labels_to_tensors(directory_path):\n",
    "    label_strings = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        artist = json.load(open(directory_path + filename, 'r'))['artist']\n",
    "        album = json.load(open(directory_path + filename, 'r'))['album']\n",
    "        label = artist + '\\n' + album;\n",
    "        print(label)\n",
    "        label_strings.append(label)\n",
    "    label_tensors = tf.Variable(label_strings)\n",
    "    return label_tensors\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, directory_path, img_height, img_width, batch_size):\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        img_directory_path = directory_path + '/img/'\n",
    "        label_directory_path = directory_path + '/json/' \n",
    "        print('Getting image data from path ', img_directory_path)\n",
    "\n",
    "        img_paths = [f for f in listdir(img_directory_path) if isfile(join(img_directory_path, f))]\n",
    "        print(img_paths)\n",
    "        self.images= images_to_tensors(img_paths)\n",
    "        print(self.images)\n",
    "        print('Getting label data from path ', label_directory_path)\n",
    "        self.labels = labels_to_tensors(label_directory_path)\n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        perm0 = numpy.arange(batch_size)\n",
    "        numpy.random.shuffle(perm0)\n",
    "        self._images = self.images[perm0]\n",
    "        self._labels = self.labels[perm0]\n",
    "        return self._images[start:end], self._labels[start:end]\n",
    "    \n",
    "    def print(self):\n",
    "        print('Printing Image Dataset')\n",
    "        fn = lambda x: print(x)\n",
    "        tf.map_fn(fn,self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting image data from path  ./dataset/train/img/\n",
      "['andrewlloydwebberandtimrice_jesuschristsuperstar_0002.JPG', 'bg_choppercityintheghetto_0001.JPG', 'bg_choppercityintheghetto_0002.JPG', 'bjork_debut_0001.JPG', 'bjork_debut_0002.JPG', 'blackflag_damaged_0001.JPG', 'blackflag_damaged_0002.JPG', 'blackflag_mywar_0001.JPG', 'blackflag_mywar_0002.JPG', 'catstevens_foreigner_0001.JPG', 'catstevens_foreigner_0002.JPG', 'catstevens_greatesthits_0001.JPG', 'catstevens_greatesthits_0002.JPG', 'charlieparker_bird-thesavoyrecordings_0001.JPG', 'charlieparker_bird-thesavoyrecordings_0002.JPG', 'charlieparker_bird-thesavoyrecordings_0003.JPG', 'charlieparker_bird-thesavoyrecordings_0004.JPG', 'cher_theverybestofcher_0001.JPG', 'cher_theverybestofcher_0002.JPG', 'chic_cestchic_0002.JPG', 'chic_chic_0001.JPG', 'chic_chic_0002.JPG', 'ciare_likeaboy_0001.JPG', 'clipping_splendor&misery_0001.JPG', 'clipping_splendor&misery_0002.JPG', 'commodores_midnightmagic_0001.JPG', 'commodores_midnightmagic_0002.JPG', 'dianarossandthesupremes_lovechild_0001.JPG', 'dianarossandthesupremes_lovechild_0002.JPG', 'dianaross_diana_0001.JPG', 'dianaross_diana_0002.JPG', 'dianaross_theboss-livinlovin&givin_0001.JPG', 'dianaross_theboss-livinlovin&givin_0002.JPG', 'donnasummer_irememberyesterday_0001.JPG', 'donnasummer_irememberyesterday_0002.JPG', 'earthwind&fire_electricuniverse_0001.JPG', 'earthwind&fire_electricuniverse_0002.JPG', 'enlightment_faithisthekey_0001.JPG', 'enlightment_faithisthekey_0002.JPG', 'eroticdrumband_poppopshoowah_0001.JPG', 'eroticdrumband_poppopshoowah_0002.JPG', 'evelynthomas_highenergy_0001.JPG', 'evelynthomas_highenergy_0002.JPG', 'frankzappa_waka-jawakahotrats_0002.JPG', 'gagle_3peat_0001.JPG', 'gagle_3peat_0002.JPG', 'gagle_3peat_0003.JPG', 'gagle_3peat_0004.JPG', 'gilscottheron_nothingnew_0002.JPG', 'gwenmccrae_onmyway_0002.JPG', 'herbiehancock_vsop_0001.JPG', 'herbiehancock_vsop_0002.JPG', 'herbiehancock_vsop_0003.JPG', 'herbiehancock_vsop_0004.JPG', 'jamesblake_enoughthunder_0001.JPG', 'jamesblake_enoughthunder_0002.JPG', 'jamesblake_jamesblake_0002.JPG', 'jamesblake_jamesblake_0003.JPG', 'jamesblake_jamesblake_0004.JPG', 'johncoltrane_alovesupreme_0001.JPG', 'johncoltrane_alovesupreme_0002.JPG', 'kanyewest_lateregistration_0001.JPG', 'kanyewest_lateregistration_0002.JPG', 'kanyewest_lateregistration_0003.JPG', 'kanyewest_lateregistration_0004.JPG', 'kennethcopeland_spiritwind_0001.JPG', 'kennethcopeland_spiritwind_0002.JPG', 'levert_thebigthrowdown_0001.JPG', 'levert_thebigthrowdown_0002.JPG', 'macdemarco_anotherone_0001.JPG', 'macdemarco_anotherone_0002.JPG', 'madvillain_madvillainy_0002.JPG', 'marvingaye_whatsgoingon_0001.JPG', 'marvingaye_whatsgoingon_0002.JPG', 'michaeljackson_offthewall_0001.JPG', 'michaeljackson_offthewall_0002.JPG', 'michaeljackson_thriller_0001.JPG', 'michaeljackson_thriller_0002.JPG', 'milesdavis_kindofblue_0001.JPG', 'milesdavis_kindofblue_0002.JPG', 'milesdavis_somedaymyprincewillcome_0001.JPG', 'milesdavis_somedaymyprincewillcome_0002.JPG', 'movieland_postcardtonewyork_0001.JPG', 'movieland_postcardtonewyork_0002.JPG', 'mrfingers_whataboutthislove_0001.JPG', 'mrfingers_whataboutthislove_0002.JPG', 'musiqsoulchild_radio_0001.JPG', 'natkingcole_natkingcoleatthesands_0001.JPG', 'natkingcole_natkingcoleatthesands_0002.JPG', 'natkingcole_thenatkingcolestoryvolumeii_0001.JPG', 'natkingcole_thenatkingcolestoryvolumeii_0002.JPG', 'odyssey_odyssey_0001.JPG', 'odyssey_odyssey_0002.JPG', 'oneohtrixpointnever_commissionsii_0001.JPG', 'oneohtrixpointnever_commissionsi_0001.JPG', 'oneohtrixpointnever_commissionsi_0002.JPG', 'pacodelucia_fridaynightinsanfrancisco_0001.JPG', 'pacodelucia_fridaynightinsanfrancisco_0002.JPG', 'rendezvous_rocknrolldiscoboogie_0001.JPG', 'rendezvous_rocknrolldiscoboogie_0002.JPG', 'simboraorchestra_brazuca_0001.JPG', 'simboraorchestra_brazuca_0002.JPG', 'steviewonder_songsinthekeyoflife_0001.JPG', 'steviewonder_songsinthekeyoflife_0002.JPG', 'steviewonder_songsinthekeyoflife_0003.JPG', 'steviewonder_songsinthekeyoflife_0004.JPG', 'stvincent_actor_0002.JPG', 'sugarhillgang_rappersdelight_0001.JPG', 'tameimpala_innerspeaker_0001.JPG', 'tameimpala_innerspeaker_0002.JPG', 'tameimpala_liveversions_0001.JPG', 'tameimpala_liveversions_0002.JPG', 'tameimpala_lonerism_0001.JPG', 'tameimpala_lonerism_0002.JPG', 'tennamarie_nakedtotheworld_0001.JPG', 'tennamarie_nakedtotheworld_0002.JPG', 'therollingstones_tattooyou_0002.JPG', 'tonalanegra_interpretaarafaelhernandezypedroflores_0001.JPG', 'tonalanegra_interpretaarafaelhernandezypedroflores_0002.JPG']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-d134e8ee7041>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./dataset/train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-36-85c4fe77934c>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory_path, img_height, img_width, batch_size)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mimg_paths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_directory_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_directory_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mimages_to_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Getting label data from path '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_directory_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-85c4fe77934c>\u001b[0m in \u001b[0;36mimages_to_tensors\u001b[1;34m(img_paths)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mfn2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "dataset_train = Dataset('./dataset/train', 256, 256, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Init Weights\n",
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=.1)\n",
    "    return tf.Variable(init_random_dist)\n",
    "\n",
    "# Init Bias\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1,shape=shape);\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "# Conv2D\n",
    "# x: [batch size, height, width, # of channels]\n",
    "# W: [height filter, width filter, # of input channels, # of output channels]\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "# Pooling\n",
    "# x: [batch size, height, width, # of channels]\n",
    "# ksize: size of the window for each dimension of the input tensor\n",
    "# strides: \n",
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1] , strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Network Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convolutional Layer\n",
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W)+b)\n",
    "\n",
    "# Normal (Fully Connected) Layer\n",
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return (tf.matmul(input_layer, W)+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Placeholders\n",
    "x = tf.placeholder(tf.float32, shape=[None, 65536])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, len(letters)])\n",
    "\n",
    "# Layers\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "convo_1 = convolutional_layer(x_image, shape=[5,5,1,32])\n",
    "pool_1 = max_pool_2by2(convo_1)\n",
    "convo_2 = convolutional_layer(pool_1, shape=[5,5,32,64])\n",
    "pool_2 = max_pool_2by2(convo_2)\n",
    "flat_1 = tf.reshape(pool_2, [-1,256*256*64])\n",
    "full_layer_one = tf.nn.relu(normal_full_layer(flat_1, 1024))\n",
    "\n",
    "# Dropout\n",
    "# used to prevent overfitting\n",
    "hold_prob = tf.placeholder(tf.float32)\n",
    "full_one_dropout = tf.nn.dropout(full_layer_one, keep_prob=hold_prob)\n",
    "y_pred = normal_full_layer(full_one_dropout, len(letters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true, logits=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = Dataset('dataset/train/', 256, 256, 50)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps = 5000\n",
    "data = Dataset('dataset/train/', 256, 256, 50)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(steps):\n",
    "        batch_x, batch_y = Dataset.next_batch(25)\n",
    "        \n",
    "        sess.run(train, feed_dict={x: batch_x, y_true: batch_y, hold_prob: 0.5})\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(\"On Step: \".format(i))\n",
    "            print(\"accuracy\");\n",
    "            \n",
    "            matches = tf.equal(tf.argmax(y-pred,1)), tf.argmax(y_true, 1)\n",
    "            acc tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "            print (sess.run(acc,feed-dict={x:Dataset.images, y:Dataset.labels, hold_prob:1.0}))\n",
    "            print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
